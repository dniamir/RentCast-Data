{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from rentcast_api import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp = RentCastPlotter.open_db(db_path='./Data/All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp.list_all_cities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(rcp.data_processed['beaverton_or'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_states = [['Portland', 'OR'],\n",
    "               ['Happy Valley', 'OR'],\n",
    "               ['Beaverton', 'OR'],\n",
    "               ['Camas', 'WA'],\n",
    "               ['Lake Oswego', 'OR'],\n",
    "               ['Tigard', 'OR'],\n",
    "               ['Gresham', 'OR'],\n",
    "               ['Oregon City', 'OR'],\n",
    "               ['Hood River', 'OR'],]\n",
    "\n",
    "filters = [\n",
    "    (\"squareFootage\", \">\", 1000),\n",
    "    (\"squareFootage\", \"<\", 4000),\n",
    "    (\"price_per_sqft\", \">\", 100),\n",
    "    (\"price_per_sqft\", \"<\", 1000),\n",
    "]\n",
    "\n",
    "rcp.plot_city_states(city_states, filters=filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp.data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "# from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data\n",
    "df = rcp.data_all\n",
    "\n",
    "# Example feature set\n",
    "num_cols = [\"bedrooms\", \"bathrooms\", \"months\"]\n",
    "cat_cols = [\"city\", \"propertyType\", \"geo_cluster\"]\n",
    "\n",
    "num_cols = [\"bedrooms\", \"bathrooms\", \"months\"]\n",
    "cat_cols = [\"city\", \"geo_cluster\", 'sale_month']\n",
    "\n",
    "# Target\n",
    "target = \"lastSalePrice\"\n",
    "\n",
    "# Drop rows missing target\n",
    "df = df.dropna(subset=[target] + num_cols)\n",
    "\n",
    "# Filter properties that are on the edges\n",
    "df_clean = df[\n",
    "    (df[\"lastSalePrice\"] < 2_000_000) &\n",
    "    (df[\"bedrooms\"].between(1, 8)) &\n",
    "    (df[\"bathrooms\"].between(1, 8)) &\n",
    "    (df[\"squareFootage\"].between(500, 6000)) &\n",
    "    (df[\"lotSize\"].between(500, 25_000)) &\n",
    "    (df[\"yearBuilt\"].between(1850, 2025)) &\n",
    "    (df[\"lastSalePrice\"] / df[\"squareFootage\"] < 2000)\n",
    "]\n",
    "\n",
    "df_clean.reset_index(drop=True, inplace=True)\n",
    "df_clean = copy.deepcopy(df_clean)\n",
    "\n",
    "# Ensure it's string and split\n",
    "df_clean[[\"sale_month\" ,\"sale_year\"]] = df_clean[\"month-year\"].str.split(\"-\", expand=True)\n",
    "df_clean['sale_year'] = df_clean['sale_year'].values.astype(int)\n",
    "\n",
    "# Convert to integers\n",
    "df_clean[\"sale_month\"] = df_clean[\"sale_month\"].astype(int)\n",
    "# df_clean[\"sale_year\"] = df_clean[\"sale_year\"].astype(int) - 1985\n",
    "\n",
    "# Get rough neighborhood\n",
    "coords = df_clean[[\"latitude\",\"longitude\"]]\n",
    "df_clean[\"geo_cluster\"] = KMeans(n_clusters=50, random_state=42).fit_predict(coords)\n",
    "cluster_means = df_clean.groupby(\"geo_cluster\")[\"lastSalePrice\"].median()\n",
    "\n",
    "\n",
    "# Normalize some of the data\n",
    "# df_clean['house_age'] = 2025 - df_clean['yearBuilt']\n",
    "# calculated_cols = ['log_lotSize', 'log_sqft', 'log_sqFt_per_bedroom', 'log_sqFt_per_bathroom', 'yearsOld', 'sale_month']\n",
    "calculated_cols = ['log_lotSize', 'log_sqft', 'yearsOld', 'log_cluster_time_median', 'lotsqft_per_sqft']\n",
    "num_cols += calculated_cols\n",
    "df_clean['log_lotSize'] = np.log(df_clean['lotSize'].values)\n",
    "df_clean['log_sqft'] = np.log(df_clean['squareFootage'].values)\n",
    "df_clean['lotsqft_per_sqft'] = np.log(df_clean['lotSize'].values / df_clean['squareFootage'].values)\n",
    "df_clean['log_sqFt_per_bedroom'] = np.log(df_clean['squareFootage'].values) / df_clean['bedrooms'].values\n",
    "df_clean['log_sqFt_per_bathroom'] = np.log(df_clean['squareFootage'].values) / df_clean['bathrooms'].values\n",
    "df_clean['yearsOld'] = 2025 - df_clean['yearBuilt'].values\n",
    "# df_clean.drop(columns=['yearBuilt', 'lotSize'], inplace=True)\n",
    "\n",
    "y = np.log1p(df_clean[target])  \n",
    "\n",
    "for cluster_id, group in df_clean.groupby(\"geo_cluster\"):\n",
    "    X_temp = group[[\"months\"]].values\n",
    "    y_temp = group[target].values\n",
    "\n",
    "    # simple linear fit\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_temp, y_temp)\n",
    "\n",
    "    # predict for this group's rows\n",
    "    df_clean.loc[group.index, \"log_cluster_time_median\"] = model.predict(X_temp)\n",
    "\n",
    "X = df_clean[num_cols + cat_cols]\n",
    "\n",
    "# Better as a target, error is in % rather than abs\n",
    "# 100k error is different for a 200k home vs a 20M home\n",
    "\n",
    "\n",
    "print(list(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Model\n",
    "# xgb = XGBRegressor(\n",
    "#     n_estimators=2000,      # number of boosting rounds (like max_iter)\n",
    "#     learning_rate=0.03,     # step size shrinkage\n",
    "#     max_depth=12,           # depth of each tree\n",
    "#     subsample=0.8,          # use 80% of rows per tree (helps generalization)\n",
    "#     colsample_bytree=0.8,   # use 80% of features per tree\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1               # use all cores\n",
    "# )\n",
    "\n",
    "hgb = HistGradientBoostingRegressor(\n",
    "    max_iter=400, \n",
    "    learning_rate=0.01, \n",
    "    max_depth=10,\n",
    "    early_stopping=True,\n",
    "    random_state=42\n",
    ")\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", hgb)\n",
    "])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validation score\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5,\n",
    "                         scoring=\"neg_root_mean_squared_error\")\n",
    "print(\"CV RMSE:\", -np.mean(scores))\n",
    "\n",
    "# Evaluate on test\n",
    "test_score = model.score(X_test, y_test)  # R^2\n",
    "print(\"Test R²:\", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_cols = num_cols + cat_cols + ['sale_year']\n",
    "\n",
    "# pick a row by index (from the same schema as training)\n",
    "i = np.random.randint(0, df_clean.shape[0])\n",
    "x_one = df_clean.loc[i:i+0, feature_cols]          # note the double brackets to keep it 2D\n",
    "pred_log = model.predict(x_one)[0]         # model outputs log-price\n",
    "pred_price = float(np.expm1(pred_log))     # back to dollars\n",
    "act_price = df_clean.loc[i, 'lastSalePrice']\n",
    "per_error = (pred_price - act_price) / act_price * 100\n",
    "\n",
    "print(\"Predicted - Actual - %% Error --- $%i - $%i - %.1f%%\" % (pred_price / 1000, act_price / 1000, per_error))\n",
    "df_clean.loc[i:i+0, feature_cols + ['lastSalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_cols = num_cols + cat_cols\n",
    "\n",
    "x_one = df_clean.loc[:, feature_cols]               # note the double brackets to keep it 2D\n",
    "actual_prices = df_clean.loc[:, 'lastSalePrice'] \n",
    "pred_log = model.predict(x_one)                     # model outputs log-price\n",
    "pred_prices = np.expm1(pred_log)                    # back to dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(pred_prices) / 1e3, np.array(actual_prices) / 1e3, lw=0, ms=4, mec='black', alpha=0.02, marker='o')\n",
    "plt.grid(True)\n",
    "\n",
    "ax = plt.gca()\n",
    "# get limits\n",
    "lims = [\n",
    "    min(ax.get_xlim()[0], ax.get_ylim()[0]),\n",
    "    max(ax.get_xlim()[1], ax.get_ylim()[1]),\n",
    "]\n",
    "\n",
    "# plot 1:1 line\n",
    "ax.plot(lims, lims, 'k--', alpha=1)  # black dashed line\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "\n",
    "plt.ylabel('Actual Cost [$1k]')\n",
    "plt.xlabel('Predicted Cost [$1k]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per = False\n",
    "\n",
    "feature_cols = num_cols + cat_cols\n",
    "\n",
    "x_one = df_clean.loc[:, feature_cols]               # note the double brackets to keep it 2D\n",
    "actual_prices = df_clean.loc[:, 'lastSalePrice'].values \n",
    "pred_log = model.predict(x_one)                     # model outputs log-price\n",
    "pred_prices = np.expm1(pred_log)   \n",
    "\n",
    "if per:\n",
    "    error = (pred_prices - actual_prices) / actual_prices * 100\n",
    "else:\n",
    "    error = (pred_prices - actual_prices) / 1000\n",
    "\n",
    "important_cols = ['months', 'squareFootage', 'sale_year', 'yearsOld', 'lastSalePrice', 'geo_cluster']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for idx, important_col in enumerate(important_cols):\n",
    "\n",
    "    col_data = df_clean.loc[:, important_col].values\n",
    "\n",
    "    if important_col == 'lastSalePrice':\n",
    "        col_data = col_data / 1e3\n",
    "\n",
    "    plt.subplot(2, 3, idx+1)\n",
    "    plt.plot(col_data, error, lw=0, ms=4, marker='o', mec='black', alpha=0.005)\n",
    "    plt.xlabel(important_col)\n",
    "    plt.grid()\n",
    "    if per:\n",
    "        plt.title('Error [%%] vs %s' % important_col)\n",
    "        plt.ylim([-200, 200])\n",
    "    else:\n",
    "        plt.title('Error [$1k] vs %s' % important_col)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def binned_residual_stats(x, err, bins=20, strategy=\"quantile\"):\n",
    "    \"\"\"\n",
    "    x: 1D array-like feature\n",
    "    err: 1D array-like residuals (e.g., (pred - actual)/actual*100 or pred-actual)\n",
    "    bins: number of bins\n",
    "    strategy: \"quantile\" (equal-count bins) or \"uniform\" (equal-width bins)\n",
    "    Returns: DataFrame with bin centers, mean, p10, p90, count\n",
    "    \"\"\"\n",
    "    x = pd.Series(x).astype(float)\n",
    "    err = pd.Series(err).astype(float)\n",
    "\n",
    "    if strategy == \"quantile\":\n",
    "        # quantile bins handle skewed features better\n",
    "        q = np.linspace(0, 1, bins + 1)\n",
    "        edges = x.quantile(q).values\n",
    "        # ensure strictly increasing (dedup if constant segments)\n",
    "        edges = np.unique(edges)\n",
    "        if len(edges) < 3:  # too few unique edges\n",
    "            edges = np.linspace(x.min(), x.max(), min(bins, 10) + 1)\n",
    "        cats = pd.cut(x, bins=edges, include_lowest=True)\n",
    "    else:\n",
    "        cats = pd.cut(x, bins=bins)\n",
    "\n",
    "    g = pd.DataFrame({\"x\": x, \"err\": err, \"bin\": cats}).dropna().groupby(\"bin\")\n",
    "    stats = g.agg(\n",
    "        x_mid=(\"x\", lambda s: (s.min() + s.max()) / 2.0),\n",
    "        err_mean=(\"err\", \"mean\"),\n",
    "        err_p10=(\"err\", lambda s: np.percentile(s, 10)),\n",
    "        err_p90=(\"err\", lambda s: np.percentile(s, 90)),\n",
    "        count=(\"err\", \"size\"),\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return stats.sort_values(\"x_mid\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_binned_residuals(x, err, feature_name, bins=20, strategy=\"quantile\",\n",
    "                          ylim=None, ax=None):\n",
    "    \"\"\"\n",
    "    Plots mean residual per bin with a shaded 10–90% band.\n",
    "    \"\"\"\n",
    "    stats = binned_residual_stats(x, err, bins=bins, strategy=strategy)\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "    ax.axhline(0, ls=\"--\", lw=1, color=\"gray\")\n",
    "    ax.fill_between(stats[\"x_mid\"], stats[\"err_p10\"], stats[\"err_p90\"],\n",
    "                    alpha=0.2, edgecolor=\"none\")\n",
    "    ax.plot(stats[\"x_mid\"], stats[\"err_mean\"], marker=\"o\", lw=2, mec='black')\n",
    "    ax.set_xlabel(feature_name)\n",
    "    ax.set_ylabel(\"Mean error\")\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    return ax, stats\n",
    "\n",
    "features_to_check = [\n",
    "    (\"months\", df_clean[\"months\"].values),\n",
    "    (\"squareFootage\", df_clean[\"squareFootage\"].values),\n",
    "    (\"lotSize\", df_clean[\"lotSize\"].values),\n",
    "    (\"yearsOld\", df_clean[\"yearsOld\"].values),\n",
    "    (\"lastSalePrice\", actual_prices),\n",
    "    (\"geoCluster\", df_clean[\"geo_cluster\"].values),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 7))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, (name, feat) in zip(axes, features_to_check):\n",
    "    plot_binned_residuals(feat, error, name, bins=25, strategy=\"quantile\",\n",
    "                          ylim=(-300, 300), ax=ax)\n",
    "\n",
    "# Hide any extra subplot\n",
    "for ax in axes[len(features_to_check):]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"Binned residuals (mean ± 10–90% band)\", y=1.02)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "feature_cols = num_cols + calculated_cols\n",
    "PartialDependenceDisplay.from_estimator(model, X_test.iloc[:1_000, :], feature_cols)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "feature_cols = num_cols + cat_cols + calculated_cols\n",
    "\n",
    "for idx, col in enumerate(feature_cols):\n",
    "\n",
    "    plt.subplot(2, 4, idx+1)\n",
    "    df_clean[col].hist(bins=30, edgecolor='black')\n",
    "    print(\"Median %s: %.2f, Max %s: %.2f\" % (col, df_clean[col].median(), col,  df_clean[col].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "y_test_mean = np.full_like(y_test, y_train.mean())\n",
    "baseline_rmse = mean_squared_error(y_test, y_test_mean)\n",
    "print(\"Baseline RMSE:\", baseline_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_clean[[\"squareFootage\",\"lotSize\",\"yearBuilt\"]].describe())\n",
    "print(df_clean[\"squareFootage\"].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "toy = LinearRegression()\n",
    "toy.fit(df_clean[[\"squareFootage\"]], df_clean[\"lastSalePrice\"])\n",
    "print(\"R² (sqft only):\", toy.score(df_clean[[\"squareFootage\"]], df_clean[\"lastSalePrice\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.mean(), y_test.mean())\n",
    "print(X_train[\"city\"].value_counts().head())\n",
    "print(X_test[\"city\"].value_counts().head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
